{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists: E:\\Deepfake detection\\Dataset\n",
      "Subfolders: ['Test', 'Train', 'Validation']\n"
     ]
    }
   ],
   "source": [
    "def load_images(data_dir, img_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(data_dir):\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        if not os.path.isdir(label_dir):\n",
    "            continue  # Skip non-directory files\n",
    "        \n",
    "        for img_file in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, img_file)\n",
    "\n",
    "            # Read the image\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {img_path}. Skipping...\")\n",
    "                continue  # Skip unreadable images\n",
    "\n",
    "            # Resize and normalize the image\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img.astype('float32') / 255.0  \n",
    "            \n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)  # Move return here\n",
    "\n",
    "# Define dataset path\n",
    "data_dir = r'E:\\Deepfake detection\\Dataset'\n",
    "\n",
    "if os.path.exists(data_dir):\n",
    "    print(\"Directory exists:\", data_dir)\n",
    "    print(\"Subfolders:\", os.listdir(data_dir))\n",
    "else:\n",
    "    print(\"Error: Dataset directory does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Fake - Found 70001 images\n",
      "Train/Real - Found 70001 images\n",
      "Total images in Train: 140002\n",
      "\n",
      "Test/Fake - Found 5492 images\n",
      "Test/Real - Found 5413 images\n",
      "Total images in Test: 10905\n",
      "\n",
      "Validation/Fake - Found 19641 images\n",
      "Validation/Real - Found 19787 images\n",
      "Total images in Validation: 39428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subset in ['Train', 'Test', 'Validation']:\n",
    "    subset_path = os.path.join(data_dir, subset)\n",
    "    \n",
    "    if os.path.exists(subset_path):\n",
    "        total_images = 0\n",
    "        for label in os.listdir(subset_path):  # Iterate over \"REAL\" and \"FAKE\" folders\n",
    "            label_dir = os.path.join(subset_path, label)\n",
    "            if os.path.isdir(label_dir):  # Ensure it's a directory\n",
    "                images = [f for f in os.listdir(label_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "                print(f\"{subset}/{label} - Found {len(images)} images\")\n",
    "                total_images += len(images)\n",
    "\n",
    "        print(f\"Total images in {subset}: {total_images}\\n\")\n",
    "    else:\n",
    "        print(f\"Error: {subset} folder not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 broken images\n"
     ]
    }
   ],
   "source": [
    "broken_images = []\n",
    "\n",
    "for subset in ['Train', 'Test', 'Validation']:\n",
    "    subset_path = os.path.join(data_dir, subset)\n",
    "    \n",
    "    for label in os.listdir(subset_path):  # Iterate over \"REAL\" and \"FAKE\"\n",
    "        label_dir = os.path.join(subset_path, label)\n",
    "        \n",
    "        for img_file in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is None: \n",
    "                broken_images.append(img_path)\n",
    "\n",
    "print(f\"Found {len(broken_images)} broken images\")\n",
    "if broken_images:\n",
    "    print(\"Example broken images:\", broken_images[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140002 files belonging to 2 classes.\n",
      "Found 39428 files belonging to 2 classes.\n",
      "Found 10905 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to dataset folders\n",
    "train_dir = r'E:\\Deepfake detection\\Dataset\\Train'\n",
    "val_dir = r'E:\\Deepfake detection\\Dataset\\Validation'\n",
    "test_dir = r'E:\\Deepfake detection\\Dataset\\Test'\n",
    "\n",
    "# Define parameters\n",
    "IMG_SIZE = (128, 128)  # Resize images to 128x128\n",
    "BATCH_SIZE = 16  # Reduce batch size to save memory\n",
    "\n",
    "# Load dataset using TensorFlow pipeline\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficient data pipeline created. No MemoryErrors!\n"
     ]
    }
   ],
   "source": [
    "# Optimize data loading\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"Efficient data pipeline created. No MemoryErrors!\")\n",
    "\n",
    "# Define CNN model\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification: Real (0) or Fake (1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,304,769\n",
      "Trainable params: 3,304,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "8751/8751 [==============================] - 1050s 120ms/step - loss: 0.6017 - accuracy: 0.7833 - val_loss: 0.4098 - val_accuracy: 0.8189\n",
      "Epoch 2/10\n",
      "8751/8751 [==============================] - 1069s 122ms/step - loss: 0.3022 - accuracy: 0.8746 - val_loss: 0.3413 - val_accuracy: 0.8611\n",
      "Epoch 3/10\n",
      "8751/8751 [==============================] - 1059s 121ms/step - loss: 0.2582 - accuracy: 0.8964 - val_loss: 0.3619 - val_accuracy: 0.8709\n",
      "Epoch 4/10\n",
      "8751/8751 [==============================] - 1036s 118ms/step - loss: 0.2436 - accuracy: 0.9039 - val_loss: 0.2786 - val_accuracy: 0.8851\n",
      "Epoch 5/10\n",
      "8751/8751 [==============================] - 1039s 119ms/step - loss: 0.2357 - accuracy: 0.9070 - val_loss: 0.2899 - val_accuracy: 0.8833\n",
      "Epoch 6/10\n",
      "8751/8751 [==============================] - 1044s 119ms/step - loss: 0.2371 - accuracy: 0.9076 - val_loss: 0.2986 - val_accuracy: 0.8830\n",
      "Epoch 7/10\n",
      "8751/8751 [==============================] - 1052s 120ms/step - loss: 0.2274 - accuracy: 0.9107 - val_loss: 0.3762 - val_accuracy: 0.8660\n",
      "Epoch 8/10\n",
      "8751/8751 [==============================] - 1072s 122ms/step - loss: 0.2252 - accuracy: 0.9122 - val_loss: 0.2900 - val_accuracy: 0.8914\n",
      "Epoch 9/10\n",
      "8751/8751 [==============================] - 1063s 122ms/step - loss: 0.2257 - accuracy: 0.9117 - val_loss: 0.2761 - val_accuracy: 0.8899\n",
      "Epoch 10/10\n",
      "8751/8751 [==============================] - 1068s 122ms/step - loss: 0.2284 - accuracy: 0.9117 - val_loss: 0.3031 - val_accuracy: 0.8918\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = create_model()\n",
    "model.summary()  # Check model architecture\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 10  \n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682/682 [==============================] - 19s 27ms/step - loss: 0.3723 - accuracy: 0.8708\n",
      "Test Accuracy: 87.08%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"E:\\Deepfake detection\\deepfake_detection_updated_v2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
